

=== Trial output start ===
Configured TICK: ['JPM', 'MSFT', 'MA', 'UNH', 'CAT', 'ADBE', 'TSLA'] (count: 7)
[Data] Using cached data from csv/prices.csv
[Macro] Excluding ^UST2Y due to low data coverage (0.00% non-NA)
Feat shape: (1584, 217), Columns: ['ret_JPM', 'price_JPM', 'momentum8_JPM', 'momentum12_JPM', 'momentum24_JPM']...
Ret shape: (1584, 7), Columns: ['ADBE', 'CAT', 'JPM', 'MA', 'MSFT']...
[Data] Training samples: 746, Validation samples: 131, Test samples: 617
[Data] Training samples: 746, Validation samples: 131, Test samples: 617
Creating TransformerTrader with dimen=217, heads=1, device=cpu
Model MLP head output dim: 7
-Epoch/Batch: 0 / 0
-Mean/SD Pen: nan / 0.004428
Loss/Mean/SD: 0.019313 / -0.000929 / 0.007229
-Epoch/Batch: 0 / 1
-Mean/SD Pen: nan / 0.015214
Loss/Mean/SD: 0.032022 / -0.001056 / 0.038328
-Epoch/Batch: 0 / 2
-Mean/SD Pen: -0.029488 / 0.021636
Loss/Mean/SD: -0.005792 / 0.010721 / 0.061683
-Epoch/Batch: 0 / 3
-Mean/SD Pen: -0.032127 / 0.016695
Loss/Mean/SD: -0.014047 / 0.014560 / 0.043452
-Epoch/Batch: 0 / 4
-Mean/SD Pen: -0.031103 / 0.013039
Loss/Mean/SD: -0.017270 / 0.012969 / 0.031115
-Epoch/Batch: 0 / 5
-Mean/SD Pen: -0.017175 / 0.010972
Loss/Mean/SD: -0.005687 / 0.001555 / 0.024640
-Epoch/Batch: 0 / 6
-Mean/SD Pen: -0.025449 / 0.007682
Loss/Mean/SD: -0.017569 / 0.006334 / 0.015221
-Epoch/Batch: 0 / 7
-Mean/SD Pen: -0.024924 / 0.007887
Loss/Mean/SD: -0.016873 / 0.005880 / 0.015773
-Epoch/Batch: 0 / 8
-Mean/SD Pen: -0.030248 / 0.009531
Loss/Mean/SD: -0.020565 / 0.011740 / 0.020373
-Epoch/Batch: 0 / 9
-Mean/SD Pen: -0.024561 / 0.008960
Loss/Mean/SD: -0.015406 / 0.005580 / 0.018740
-Epoch/Batch: 0 / 10
-Mean/SD Pen: -0.030247 / 0.014954
Loss/Mean/SD: -0.014630 / 0.011738 / 0.037444
-Epoch/Batch: 0 / 11
-Mean/SD Pen: -0.028461 / 0.012682
Loss/Mean/SD: -0.015128 / 0.009446 / 0.029971
-Epoch/Batch: 0 / 12
-Mean/SD Pen: -0.035566 / 0.013142
Loss/Mean/SD: -0.022068 / 0.020936 / 0.031446
-Epoch/Batch: 0 / 13
-Mean/SD Pen: -0.025167 / 0.007815
Loss/Mean/SD: -0.017182 / 0.006088 / 0.015578
-Epoch/Batch: 0 / 14
-Mean/SD Pen: nan / 0.002644
Loss/Mean/SD: 0.015472 / -0.000536 / 0.003601
-Epoch/Batch: 1 / 0
-Mean/SD Pen: nan / 0.006070
Loss/Mean/SD: 0.019834 / -0.000689 / 0.011072
-Epoch/Batch: 1 / 1
-Mean/SD Pen: -0.029576 / 0.008437
Loss/Mean/SD: -0.020975 / 0.010835 / 0.017278
-Epoch/Batch: 1 / 2
-Mean/SD Pen: -0.027461 / 0.011620
Loss/Mean/SD: -0.015441 / 0.008312 / 0.026628
-Epoch/Batch: 1 / 3
-Mean/SD Pen: -0.033005 / 0.011268
Loss/Mean/SD: -0.021380 / 0.016030 / 0.025545
-Epoch/Batch: 1 / 4
-Mean/SD Pen: -0.028859 / 0.010260
Loss/Mean/SD: -0.018338 / 0.009925 / 0.022505
-Epoch/Batch: 1 / 5
-Mean/SD Pen: -0.021434 / 0.010481
Loss/Mean/SD: -0.010801 / 0.003431 / 0.023164
-Epoch/Batch: 1 / 6
-Mean/SD Pen: -0.024730 / 0.007044
Loss/Mean/SD: -0.017610 / 0.005718 / 0.013538
-Epoch/Batch: 1 / 7
-Mean/SD Pen: -0.024937 / 0.007637
Loss/Mean/SD: -0.017251 / 0.005891 / 0.015101
-Epoch/Batch: 1 / 8
-Mean/SD Pen: -0.025685 / 0.006874
Loss/Mean/SD: -0.018775 / 0.006547 / 0.013100
-Epoch/Batch: 1 / 9
-Mean/SD Pen: -0.025133 / 0.006163
Loss/Mean/SD: -0.018945 / 0.006058 / 0.011303
-Epoch/Batch: 1 / 10
-Mean/SD Pen: -0.028373 / 0.006956
Loss/Mean/SD: -0.021394 / 0.009341 / 0.013310
-Epoch/Batch: 1 / 11
-Mean/SD Pen: -0.023897 / 0.006783
Loss/Mean/SD: -0.017096 / 0.005060 / 0.012864
-Epoch/Batch: 1 / 12
-Mean/SD Pen: -0.027921 / 0.006577
Loss/Mean/SD: -0.021311 / 0.008821 / 0.012339
-Epoch/Batch: 1 / 13
-Mean/SD Pen: -0.025326 / 0.006146
Loss/Mean/SD: -0.019154 / 0.006226 / 0.011261
-Epoch/Batch: 1 / 14
-Mean/SD Pen: -0.030939 / 0.009528
Loss/Mean/SD: -0.021343 / 0.012726 / 0.020363
-Epoch/Batch: 2 / 0
-Mean/SD Pen: -0.028400 / 0.005603
Loss/Mean/SD: -0.022738 / 0.009373 / 0.009938
-Epoch/Batch: 2 / 1
-Mean/SD Pen: -0.029411 / 0.007540
Loss/Mean/SD: -0.021775 / 0.010621 / 0.014844
-Epoch/Batch: 2 / 2
-Mean/SD Pen: -0.025081 / 0.007451
Loss/Mean/SD: -0.017524 / 0.006013 / 0.014607
-Epoch/Batch: 2 / 3
-Mean/SD Pen: -0.028563 / 0.006831
Loss/Mean/SD: -0.021622 / 0.009567 / 0.012988
-Epoch/Batch: 2 / 4
-Mean/SD Pen: -0.022860 / 0.006952
Loss/Mean/SD: -0.015801 / 0.004318 / 0.013300
-Epoch/Batch: 2 / 5
-Mean/SD Pen: -0.028189 / 0.007021
Loss/Mean/SD: -0.021086 / 0.009127 / 0.013479
-Epoch/Batch: 2 / 6
-Mean/SD Pen: -0.027375 / 0.005001
Loss/Mean/SD: -0.022316 / 0.008220 / 0.008523
-Epoch/Batch: 2 / 7
-Mean/SD Pen: -0.025187 / 0.006078
Loss/Mean/SD: -0.019046 / 0.006105 / 0.011093
-Epoch/Batch: 2 / 8
-Mean/SD Pen: -0.025455 / 0.005410
Loss/Mean/SD: -0.019981 / 0.006340 / 0.009476
-Epoch/Batch: 2 / 9
-Mean/SD Pen: -0.023623 / 0.006994
Loss/Mean/SD: -0.016558 / 0.004856 / 0.013409
-Epoch/Batch: 2 / 10
-Mean/SD Pen: -0.028701 / 0.007231
Loss/Mean/SD: -0.021399 / 0.009733 / 0.014026
-Epoch/Batch: 2 / 11
-Mean/SD Pen: -0.025354 / 0.006157
Loss/Mean/SD: -0.019129 / 0.006250 / 0.011287
-Epoch/Batch: 2 / 12
-Mean/SD Pen: -0.028764 / 0.006934
Loss/Mean/SD: -0.021751 / 0.009809 / 0.013253
-Epoch/Batch: 2 / 13
-Mean/SD Pen: -0.029056 / 0.005563
Loss/Mean/SD: -0.023423 / 0.010169 / 0.009841
-Epoch/Batch: 2 / 14
-Mean/SD Pen: -0.026223 / 0.003356
Loss/Mean/SD: -0.022845 / 0.007050 / 0.004971
-Epoch/Batch: 3 / 0
-Mean/SD Pen: -0.026498 / 0.006730
Loss/Mean/SD: -0.019705 / 0.007317 / 0.012730
-Epoch/Batch: 3 / 1
-Mean/SD Pen: -0.027332 / 0.006823
Loss/Mean/SD: -0.020428 / 0.008174 / 0.012968
-Epoch/Batch: 3 / 2
-Mean/SD Pen: -0.027111 / 0.006321
Loss/Mean/SD: -0.020706 / 0.007940 / 0.011695
-Epoch/Batch: 3 / 3
-Mean/SD Pen: -0.029051 / 0.006985
Loss/Mean/SD: -0.021969 / 0.010163 / 0.013386
-Epoch/Batch: 3 / 4
-Mean/SD Pen: -0.028463 / 0.005697
Loss/Mean/SD: -0.022700 / 0.009448 / 0.010163
-Epoch/Batch: 3 / 5
-Mean/SD Pen: -0.026948 / 0.005835
Loss/Mean/SD: -0.021029 / 0.007771 / 0.010498
-Epoch/Batch: 3 / 6
-Mean/SD Pen: -0.023727 / 0.007172
Loss/Mean/SD: -0.016431 / 0.004933 / 0.013872
-Epoch/Batch: 3 / 7
-Mean/SD Pen: -0.026665 / 0.006961
Loss/Mean/SD: -0.019607 / 0.007484 / 0.013323
-Epoch/Batch: 3 / 8
-Mean/SD Pen: -0.023159 / 0.005519
Loss/Mean/SD: -0.017541 / 0.004523 / 0.009736
-Epoch/Batch: 3 / 9
-Mean/SD Pen: -0.028181 / 0.006243
Loss/Mean/SD: -0.021878 / 0.009118 / 0.011501
-Epoch/Batch: 3 / 10
-Mean/SD Pen: -0.027021 / 0.004982
Loss/Mean/SD: -0.021969 / 0.007846 / 0.008477
-Epoch/Batch: 3 / 11
-Mean/SD Pen: -0.026801 / 0.005524
Loss/Mean/SD: -0.021211 / 0.007621 / 0.009748
-Epoch/Batch: 3 / 12
-Mean/SD Pen: -0.028356 / 0.006807
Loss/Mean/SD: -0.021449 / 0.009322 / 0.012927
-Epoch/Batch: 3 / 13
-Mean/SD Pen: -0.027397 / 0.006329
Loss/Mean/SD: -0.020987 / 0.008243 / 0.011715
-Epoch/Batch: 3 / 14
-Mean/SD Pen: -0.021453 / 0.004507
Loss/Mean/SD: -0.016881 / 0.003442 / 0.007405
[Data] Using cached data from csv/prices.csv
[Cross-Momentum] Failed for JPM: 'close'
[Cross-Rank] Failed for JPM: 'close'
[Cross-Momentum] Failed for MSFT: 'close'
[Cross-Rank] Failed for MSFT: 'close'
[Cross-Momentum] Failed for MA: 'close'
[Cross-Rank] Failed for MA: 'close'
[Cross-Momentum] Failed for UNH: 'close'
[Cross-Rank] Failed for UNH: 'close'
[Cross-Momentum] Failed for CAT: 'close'
[Cross-Rank] Failed for CAT: 'close'
[Cross-Momentum] Failed for ADBE: 'close'
[Cross-Rank] Failed for ADBE: 'close'
[Cross-Momentum] Failed for TSLA: 'close'
[Cross-Rank] Failed for TSLA: 'close'
/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
Traceback (most recent call last):
  File "/Users/diegomontemayor/algo_trader/model.py", line 102, in <module>
    results = run_btest(device=DEVICE,initial_capital=INITIAL_CAPITAL,
  File "/Users/diegomontemayor/algo_trader/test.py", line 28, in run_btest
    feat_df, ret_df = comp_feat(TICK, feat, cached_data, macro_keys)
  File "/Users/diegomontemayor/algo_trader/feat.py", line 87, in comp_feat
    if ret.iloc[-1].isna().all():
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexing.py", line 1191, in __getitem__
    return self._getitem_axis(maybe_callable, axis=axis)
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexing.py", line 1752, in _getitem_axis
    self._validate_integer(key, axis)
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexing.py", line 1685, in _validate_integer
    raise IndexError("single positional indexer is out-of-bounds")
IndexError: single positional indexer is out-of-bounds

=== Trial output end ===


=== Trial output start ===
Configured TICK: ['MSFT', 'NVDA', 'AVGO', 'XOM', 'CAT', 'ADBE'] (count: 6)
[Data] Using cached data from csv/prices.csv
Feat shape: (1584, 219), Columns: ['ret_MSFT', 'roll_ret8_MSFT', 'roll_ret12_MSFT', 'roll_ret24_MSFT', 'ema8_MSFT']...
Ret shape: (1584, 6), Columns: ['ADBE', 'AVGO', 'CAT', 'MSFT', 'NVDA']...
[Data] Training samples: 746, Validation samples: 131, Test samples: 617
[Data] Training samples: 746, Validation samples: 131, Test samples: 617
Creating TransformerTrader with dimen=219, heads=1, device=cpu
Model MLP head output dim: 6
-Epoch/Batch: 0 / 0
-Mean/SD Pen: -0.012698 / 0.002903
Loss/Mean/SD: -0.009779 / 0.000529 / 0.004087
-Epoch/Batch: 0 / 1
-Mean/SD Pen: nan / 0.013865
Loss/Mean/SD: 0.035542 / -0.003452 / 0.033808
-Epoch/Batch: 0 / 2
-Mean/SD Pen: -0.032628 / 0.014564
Loss/Mean/SD: -0.017766 / 0.015386 / 0.036131
-Epoch/Batch: 0 / 3
-Mean/SD Pen: -0.023563 / 0.017279
Loss/Mean/SD: -0.005414 / 0.004812 / 0.045520
-Epoch/Batch: 0 / 4
-Mean/SD Pen: -0.030169 / 0.015944
Loss/Mean/SD: -0.013096 / 0.011631 / 0.040832
-Epoch/Batch: 0 / 5
-Mean/SD Pen: -0.027054 / 0.014917
Loss/Mean/SD: -0.011197 / 0.007881 / 0.037320
-Epoch/Batch: 0 / 6
-Mean/SD Pen: -0.031574 / 0.010605
Loss/Mean/SD: -0.020393 / 0.013685 / 0.023536
-Epoch/Batch: 0 / 7
-Mean/SD Pen: -0.019941 / 0.009400
Loss/Mean/SD: -0.010239 / 0.002651 / 0.019996
-Epoch/Batch: 0 / 8
-Mean/SD Pen: -0.023612 / 0.007622
Loss/Mean/SD: -0.015910 / 0.004848 / 0.015061
-Epoch/Batch: 0 / 9
-Mean/SD Pen: -0.014585 / 0.006282
Loss/Mean/SD: -0.008281 / 0.000868 / 0.011599
-Epoch/Batch: 0 / 10
-Mean/SD Pen: -0.022157 / 0.008241
Loss/Mean/SD: -0.013856 / 0.003863 / 0.016737
-Epoch/Batch: 0 / 11
-Mean/SD Pen: -0.021542 / 0.009160
Loss/Mean/SD: -0.012256 / 0.003493 / 0.019309
-Epoch/Batch: 0 / 12
-Mean/SD Pen: -0.018505 / 0.010427
Loss/Mean/SD: -0.007924 / 0.002030 / 0.023003
-Epoch/Batch: 0 / 13
-Mean/SD Pen: -0.027513 / 0.009282
Loss/Mean/SD: -0.018103 / 0.008369 / 0.019655
-Epoch/Batch: 0 / 14
-Mean/SD Pen: -0.018771 / 0.004659
Loss/Mean/SD: -0.014052 / 0.002136 / 0.007744
-Epoch/Batch: 1 / 0
-Mean/SD Pen: -0.028324 / 0.006758
Loss/Mean/SD: -0.021512 / 0.009284 / 0.012802
-Epoch/Batch: 1 / 1
-Mean/SD Pen: -0.028664 / 0.009990
Loss/Mean/SD: -0.018639 / 0.009688 / 0.021709
-Epoch/Batch: 1 / 2
-Mean/SD Pen: -0.026504 / 0.008257
Loss/Mean/SD: -0.018187 / 0.007324 / 0.016781
-Epoch/Batch: 1 / 3
-Mean/SD Pen: -0.028265 / 0.007625
Loss/Mean/SD: -0.020522 / 0.009215 / 0.015069
-Epoch/Batch: 1 / 4
-Mean/SD Pen: -0.026828 / 0.006971
Loss/Mean/SD: -0.019688 / 0.007649 / 0.013350
-Epoch/Batch: 1 / 5
-Mean/SD Pen: -0.026960 / 0.007388
Loss/Mean/SD: -0.019364 / 0.007784 / 0.014439
-Epoch/Batch: 1 / 6
-Mean/SD Pen: -0.030915 / 0.008077
Loss/Mean/SD: -0.022651 / 0.012690 / 0.016288
-Epoch/Batch: 1 / 7
-Mean/SD Pen: -0.027877 / 0.007053
Loss/Mean/SD: -0.020688 / 0.008771 / 0.013563
-Epoch/Batch: 1 / 8
-Mean/SD Pen: -0.026952 / 0.007123
Loss/Mean/SD: -0.019735 / 0.007776 / 0.013743
-Epoch/Batch: 1 / 9
-Mean/SD Pen: -0.028055 / 0.007326
Loss/Mean/SD: -0.020673 / 0.008973 / 0.014277
-Epoch/Batch: 1 / 10
-Mean/SD Pen: -0.025292 / 0.006141
Loss/Mean/SD: -0.019100 / 0.006196 / 0.011247
-Epoch/Batch: 1 / 11
-Mean/SD Pen: -0.027320 / 0.007049
Loss/Mean/SD: -0.020197 / 0.008161 / 0.013551
-Epoch/Batch: 1 / 12
-Mean/SD Pen: -0.026422 / 0.006805
Loss/Mean/SD: -0.019527 / 0.007243 / 0.012921
-Epoch/Batch: 1 / 13
-Mean/SD Pen: -0.023930 / 0.005764
Loss/Mean/SD: -0.018100 / 0.005085 / 0.010325
-Epoch/Batch: 1 / 14
-Mean/SD Pen: -0.023451 / 0.003126
Loss/Mean/SD: -0.020308 / 0.004731 / 0.004515
-Epoch/Batch: 2 / 0
-Mean/SD Pen: -0.026911 / 0.005801
Loss/Mean/SD: -0.021046 / 0.007733 / 0.010416
-Epoch/Batch: 2 / 1
-Mean/SD Pen: -0.023271 / 0.006794
Loss/Mean/SD: -0.016401 / 0.004602 / 0.012893
-Epoch/Batch: 2 / 2
-Mean/SD Pen: -0.027489 / 0.005265
Loss/Mean/SD: -0.022179 / 0.008343 / 0.009136
-Epoch/Batch: 2 / 3
-Mean/SD Pen: -0.026826 / 0.006156
Loss/Mean/SD: -0.020633 / 0.007646 / 0.011285
-Epoch/Batch: 2 / 4
-Mean/SD Pen: -0.025680 / 0.004308
Loss/Mean/SD: -0.021340 / 0.006542 / 0.006967
-Epoch/Batch: 2 / 5
-Mean/SD Pen: -0.026420 / 0.005566
Loss/Mean/SD: -0.020798 / 0.007241 / 0.009849
-Epoch/Batch: 2 / 6
-Mean/SD Pen: -0.028694 / 0.006645
Loss/Mean/SD: -0.021953 / 0.009724 / 0.012514
-Epoch/Batch: 2 / 7
-Mean/SD Pen: -0.026089 / 0.006699
Loss/Mean/SD: -0.019245 / 0.006922 / 0.012651
-Epoch/Batch: 2 / 8
-Mean/SD Pen: -0.026396 / 0.005449
Loss/Mean/SD: -0.020785 / 0.007217 / 0.009570
-Epoch/Batch: 2 / 9
-Mean/SD Pen: -0.025556 / 0.005898
Loss/Mean/SD: -0.019530 / 0.006431 / 0.010650
-Epoch/Batch: 2 / 10
-Mean/SD Pen: -0.025714 / 0.006146
Loss/Mean/SD: -0.019462 / 0.006574 / 0.011260
-Epoch/Batch: 2 / 11
-Mean/SD Pen: -0.025324 / 0.004453
Loss/Mean/SD: -0.020801 / 0.006224 / 0.007285
-Epoch/Batch: 2 / 12
-Mean/SD Pen: -0.025213 / 0.003851
Loss/Mean/SD: -0.021321 / 0.006127 / 0.005987
-Epoch/Batch: 2 / 13
-Mean/SD Pen: -0.024111 / 0.003920
Loss/Mean/SD: -0.020168 / 0.005223 / 0.006132
-Epoch/Batch: 2 / 14
-Mean/SD Pen: -0.023556 / 0.003628
Loss/Mean/SD: -0.019912 / 0.004806 / 0.005524
[Data] Using cached data from csv/prices.csv
[Cross-Momentum] Failed for MSFT: 'close'
[Cross-Rank] Failed for MSFT: 'close'
[Cross-Momentum] Failed for NVDA: 'close'
[Cross-Rank] Failed for NVDA: 'close'
[Cross-Momentum] Failed for AVGO: 'close'
[Cross-Rank] Failed for AVGO: 'close'
[Cross-Momentum] Failed for XOM: 'close'
[Cross-Rank] Failed for XOM: 'close'
[Cross-Momentum] Failed for CAT: 'close'
[Cross-Rank] Failed for CAT: 'close'
[Cross-Momentum] Failed for ADBE: 'close'
[Cross-Rank] Failed for ADBE: 'close'
/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
Traceback (most recent call last):
  File "/Users/diegomontemayor/algo_trader/model.py", line 102, in <module>
    results = run_btest(device=DEVICE,initial_capital=INITIAL_CAPITAL,
  File "/Users/diegomontemayor/algo_trader/test.py", line 28, in run_btest
    feat_df, ret_df = comp_feat(TICK, feat, cached_data, macro_keys)
  File "/Users/diegomontemayor/algo_trader/feat.py", line 87, in comp_feat
    if ret.iloc[-1].isna().all():
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexing.py", line 1191, in __getitem__
    return self._getitem_axis(maybe_callable, axis=axis)
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexing.py", line 1752, in _getitem_axis
    self._validate_integer(key, axis)
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexing.py", line 1685, in _validate_integer
    raise IndexError("single positional indexer is out-of-bounds")
IndexError: single positional indexer is out-of-bounds

=== Trial output end ===


=== Trial output start ===
Configured TICK: ['MSFT', 'AVGO', 'COST', 'MA', 'XOM', 'AMZN', 'ADBE'] (count: 7)
[Data] Downloading price and macro data...
[Data] Cached to csv/prices.csv
[Macro] Excluding ^UST2Y due to low data coverage (0.00% non-NA)
Feat shape: (1584, 252), Columns: ['ret_MSFT', 'price_MSFT', 'momentum8_MSFT', 'momentum12_MSFT', 'momentum24_MSFT']...
Ret shape: (1584, 7), Columns: ['ADBE', 'AMZN', 'AVGO', 'COST', 'MA']...
[Data] Training samples: 746, Validation samples: 131, Test samples: 617
[Data] Training samples: 746, Validation samples: 131, Test samples: 617
Creating TransformerTrader with dimen=252, heads=1, device=cpu
Model MLP head output dim: 7
-Epoch/Batch: 0 / 0
-Mean/SD Pen: nan / 0.003368
Loss/Mean/SD: 0.015236 / -0.000415 / 0.004995
-Epoch/Batch: 0 / 1
-Mean/SD Pen: -0.024085 / 0.010195
Loss/Mean/SD: -0.013641 / 0.005203 / 0.022314
-Epoch/Batch: 0 / 2
-Mean/SD Pen: -0.024452 / 0.009335
Loss/Mean/SD: -0.014746 / 0.005492 / 0.019809
-Epoch/Batch: 0 / 3
-Mean/SD Pen: -0.029543 / 0.013532
Loss/Mean/SD: -0.015165 / 0.010792 / 0.032714
-Epoch/Batch: 0 / 4
-Mean/SD Pen: -0.028335 / 0.013112
Loss/Mean/SD: -0.014582 / 0.009297 / 0.031351
-Epoch/Batch: 0 / 5
-Mean/SD Pen: -0.015285 / 0.013445
Loss/Mean/SD: -0.001484 / 0.001026 / 0.032430
-Epoch/Batch: 0 / 6
-Mean/SD Pen: -0.028803 / 0.011312
Loss/Mean/SD: -0.016879 / 0.009857 / 0.025678
-Epoch/Batch: 0 / 7
-Mean/SD Pen: -0.029415 / 0.011358
Loss/Mean/SD: -0.017355 / 0.010625 / 0.025821
-Epoch/Batch: 0 / 8
-Mean/SD Pen: -0.021441 / 0.009473
Loss/Mean/SD: -0.011371 / 0.003435 / 0.020206
-Epoch/Batch: 0 / 9
-Mean/SD Pen: -0.025572 / 0.011547
Loss/Mean/SD: -0.013839 / 0.006445 / 0.026403
-Epoch/Batch: 0 / 10
-Mean/SD Pen: -0.021573 / 0.010040
Loss/Mean/SD: -0.011479 / 0.003511 / 0.021856
-Epoch/Batch: 0 / 11
-Mean/SD Pen: -0.028857 / 0.008555
Loss/Mean/SD: -0.020220 / 0.009923 / 0.017606
-Epoch/Batch: 0 / 12
-Mean/SD Pen: -0.016052 / 0.011066
Loss/Mean/SD: -0.004892 / 0.001221 / 0.024928
-Epoch/Batch: 0 / 13
-Mean/SD Pen: -0.023604 / 0.013043
Loss/Mean/SD: -0.009817 / 0.004842 / 0.031127
-Epoch/Batch: 0 / 14
-Mean/SD Pen: -0.046205 / 0.009277
Loss/Mean/SD: -0.035440 / 0.053307 / 0.019643
-Epoch/Batch: 1 / 0
-Mean/SD Pen: -0.036997 / 0.016953
Loss/Mean/SD: -0.018602 / 0.024102 / 0.044363
-Epoch/Batch: 1 / 1
-Mean/SD Pen: -0.028413 / 0.018016
Loss/Mean/SD: -0.009089 / 0.009388 / 0.048163
-Epoch/Batch: 1 / 2
-Mean/SD Pen: -0.029389 / 0.015291
Loss/Mean/SD: -0.013131 / 0.010593 / 0.038590
-Epoch/Batch: 1 / 3
-Mean/SD Pen: -0.030919 / 0.009934
Loss/Mean/SD: -0.020407 / 0.012697 / 0.021546
-Epoch/Batch: 1 / 4
-Mean/SD Pen: -0.031456 / 0.009383
Loss/Mean/SD: -0.021733 / 0.013503 / 0.019947
-Epoch/Batch: 1 / 5
-Mean/SD Pen: -0.027832 / 0.008825
Loss/Mean/SD: -0.018773 / 0.008721 / 0.018359
-Epoch/Batch: 1 / 6
-Mean/SD Pen: -0.026457 / 0.007771
Loss/Mean/SD: -0.018631 / 0.007277 / 0.015461
-Epoch/Batch: 1 / 7
-Mean/SD Pen: -0.022760 / 0.007798
Loss/Mean/SD: -0.014903 / 0.004251 / 0.015532
-Epoch/Batch: 1 / 8
-Mean/SD Pen: -0.029211 / 0.007660
Loss/Mean/SD: -0.021439 / 0.010365 / 0.015164
-Epoch/Batch: 1 / 9
-Mean/SD Pen: -0.023795 / 0.006583
Loss/Mean/SD: -0.017083 / 0.004983 / 0.012354
-Epoch/Batch: 1 / 10
-Mean/SD Pen: -0.030984 / 0.007792
Loss/Mean/SD: -0.023011 / 0.012793 / 0.015518
-Epoch/Batch: 1 / 11
-Mean/SD Pen: -0.028105 / 0.007323
Loss/Mean/SD: -0.020624 / 0.009030 / 0.014268
-Epoch/Batch: 1 / 12
-Mean/SD Pen: -0.028884 / 0.007168
Loss/Mean/SD: -0.021606 / 0.009956 / 0.013862
-Epoch/Batch: 1 / 13
-Mean/SD Pen: -0.027707 / 0.005751
Loss/Mean/SD: -0.021817 / 0.008582 / 0.010293
-Epoch/Batch: 1 / 14
-Mean/SD Pen: -0.030717 / 0.004272
Loss/Mean/SD: -0.026316 / 0.012402 / 0.006888
-Epoch/Batch: 2 / 0
-Mean/SD Pen: -0.029377 / 0.005810
Loss/Mean/SD: -0.023475 / 0.010576 / 0.010437
-Epoch/Batch: 2 / 1
-Mean/SD Pen: -0.026419 / 0.006546
Loss/Mean/SD: -0.019784 / 0.007240 / 0.012262
-Epoch/Batch: 2 / 2
-Mean/SD Pen: -0.027489 / 0.005387
Loss/Mean/SD: -0.022008 / 0.008343 / 0.009424
-Epoch/Batch: 2 / 3
-Mean/SD Pen: -0.027468 / 0.005836
Loss/Mean/SD: -0.021550 / 0.008320 / 0.010501
-Epoch/Batch: 2 / 4
-Mean/SD Pen: -0.025865 / 0.005594
Loss/Mean/SD: -0.020144 / 0.006712 / 0.009915
-Epoch/Batch: 2 / 5
-Mean/SD Pen: -0.027637 / 0.005407
Loss/Mean/SD: -0.022086 / 0.008505 / 0.009470
-Epoch/Batch: 2 / 6
-Mean/SD Pen: -0.027113 / 0.005833
Loss/Mean/SD: -0.021155 / 0.007942 / 0.010491
-Epoch/Batch: 2 / 7
-Mean/SD Pen: -0.025266 / 0.005588
Loss/Mean/SD: -0.019586 / 0.006173 / 0.009902
-Epoch/Batch: 2 / 8
-Mean/SD Pen: -0.028107 / 0.005805
Loss/Mean/SD: -0.022180 / 0.009032 / 0.010424
-Epoch/Batch: 2 / 9
-Mean/SD Pen: -0.029249 / 0.006631
Loss/Mean/SD: -0.022520 / 0.010413 / 0.012478
-Epoch/Batch: 2 / 10
-Mean/SD Pen: -0.026421 / 0.006440
Loss/Mean/SD: -0.019910 / 0.007242 / 0.011994
-Epoch/Batch: 2 / 11
-Mean/SD Pen: -0.025658 / 0.004575
Loss/Mean/SD: -0.021028 / 0.006522 / 0.007557
-Epoch/Batch: 2 / 12
-Mean/SD Pen: -0.026357 / 0.004720
Loss/Mean/SD: -0.021589 / 0.007179 / 0.007882
-Epoch/Batch: 2 / 13
-Mean/SD Pen: -0.026592 / 0.004923
Loss/Mean/SD: -0.021614 / 0.007411 / 0.008343
-Epoch/Batch: 2 / 14
-Mean/SD Pen: -0.028388 / 0.007154
Loss/Mean/SD: -0.021189 / 0.009359 / 0.013826
[Data] Using cached data from csv/prices.csv
[Cross-Rank] Failed for MSFT: 'close'
[Cross-Rank] Failed for AVGO: 'close'
[Cross-Rank] Failed for COST: 'close'
[Cross-Rank] Failed for MA: 'close'
[Cross-Rank] Failed for XOM: 'close'
[Cross-Rank] Failed for AMZN: 'close'
[Cross-Rank] Failed for ADBE: 'close'
[Macro] Excluding ^UST2Y due to low data coverage (0.00% non-NA)
[Chunk Merge] Merging short final chunk (2025-01-01 to 2025-07-01) into previous.
[BTest] Chunk 1: Pfo Metrics: {'cagr': 0.7598359677555084, 'sharpe': 1.8521875970276394, 'max_down': -0.20422725053576446}
[BTest] Chunk 1: Bench Metrics: {'cagr': 0.535700825523274, 'sharpe': 2.550419577607526, 'max_down': -0.08619971583111169}
[BTest] Chunk 2: Pfo Metrics: {'cagr': 0.7929935965985904, 'sharpe': 1.6949841238307255, 'max_down': -0.26038777708205996}
[BTest] Chunk 2: Bench Metrics: {'cagr': 0.26698128702186175, 'sharpe': 1.2656991094626875, 'max_down': -0.19605476100039965}
[BTest] Saved perf report to img/btest_report.txt

Sharpe Ratio: Strat: 175.000603%
Sharpe Ratio: Bench: 171.029683%
Max Down: Strat: -26.038778%
Max Down: Bench: -19.605476%
CAGR: Strat: 77.935538%
CAGR: Bench: 36.330476%

Total Exp Delta: 3351.3918
Avg Bench Outperf thru Chunks:
cagr: 37.507373%
sharpe: -13.447348%
max_down: -9.118028%

[                       0%                       ]
[*******               15%                       ]  2 of 13 completed
[***********           23%                       ]  3 of 13 completed
[***************       31%                       ]  4 of 13 completed
[******************    38%                       ]  5 of 13 completed
[******************    38%                       ]  5 of 13 completed
[**********************54%*                      ]  7 of 13 completed
[**********************62%*****                  ]  8 of 13 completed
[**********************69%********               ]  9 of 13 completed
[**********************77%************           ]  10 of 13 completed
[**********************85%****************       ]  11 of 13 completed
[**********************92%*******************    ]  12 of 13 completed
[*********************100%***********************]  13 of 13 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed
HTTP Error 404: 

[*********************100%***********************]  1 of 1 completed

1 Failed download:
['PPIACO']: YFTzMissingError('possibly delisted; no timezone found')
HTTP Error 404: 

[*********************100%***********************]  1 of 1 completed

1 Failed download:
['CPIAUCSL']: YFTzMissingError('possibly delisted; no timezone found')

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

1 Failed download:
['^UST2Y']: YFTzMissingError('possibly delisted; no timezone found')

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed

[*********************100%***********************]  1 of 1 completed
/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")

=== Trial output end ===


=== Trial output start ===
Configured TICK: ['JPM', 'MSFT', 'LLY', 'MA', 'XOM', 'TSLA'] (count: 6)
[Data] Using cached data from csv/prices.csv
Traceback (most recent call last):
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'momentum8'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/diegomontemayor/algo_trader/model.py", line 95, in <module>
    feat, ret = comp_feat(TICK, feat_list, cached_data, macro_keys)
  File "/Users/diegomontemayor/algo_trader/feat.py", line 93, in comp_feat
    feat_func(df)
  File "/Users/diegomontemayor/algo_trader/feat_list.py", line 50, in add_acceleration
    data[f'acceleration{p}'] = data[f'momentum{p}'].diff()
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/frame.py", line 4107, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3819, in get_loc
    raise KeyError(key) from err
KeyError: 'momentum8'

=== Trial output end ===


=== Trial output start ===
Configured TICK: ['JPM', 'LLY', 'MA'] (count: 3)
[Data] Using cached data from csv/prices.csv
[Macro] Excluding PPIACO due to low data coverage (0.00% non-NA)
[Macro] Excluding ^UST2Y due to low data coverage (0.00% non-NA)
Feat shape: (1606, 188), Columns: ['ret_JPM', 'price_JPM', 'roll_ret8_JPM', 'roll_ret12_JPM', 'roll_ret24_JPM']...
Ret shape: (1606, 3), Columns: ['JPM', 'LLY', 'MA']...
[Data] Training samples: 765, Validation samples: 134, Test samples: 617
[Data] Training samples: 765, Validation samples: 134, Test samples: 617
Creating TransformerTrader with dimen=188, heads=1, device=cpu
Model MLP head output dim: 3
-Epoch/Batch: 0 / 0
-Mean/SD Pen: -0.011058 / 0.002641
Loss/Mean/SD: -0.008414 / 0.000323 / 0.003597
-Epoch/Batch: 0 / 1
-Mean/SD Pen: -0.015772 / 0.006720
Loss/Mean/SD: -0.008842 / 0.001147 / 0.012704
-Epoch/Batch: 0 / 2
-Mean/SD Pen: -0.024156 / 0.010806
Loss/Mean/SD: -0.012975 / 0.005258 / 0.024138
-Epoch/Batch: 0 / 3
-Mean/SD Pen: -0.026661 / 0.009536
Loss/Mean/SD: -0.016786 / 0.007480 / 0.020386
-Epoch/Batch: 0 / 4
-Mean/SD Pen: -0.026255 / 0.010214
Loss/Mean/SD: -0.015636 / 0.007081 / 0.022369
-Epoch/Batch: 0 / 5
-Mean/SD Pen: -0.022458 / 0.010158
Loss/Mean/SD: -0.012011 / 0.004053 / 0.022205
-Epoch/Batch: 0 / 6
-Mean/SD Pen: -0.026743 / 0.010093
Loss/Mean/SD: -0.016503 / 0.007562 / 0.022013
-Epoch/Batch: 0 / 7
-Mean/SD Pen: -0.026237 / 0.008043
Loss/Mean/SD: -0.018088 / 0.007063 / 0.016195
-Epoch/Batch: 0 / 8
-Mean/SD Pen: -0.019460 / 0.007774
Loss/Mean/SD: -0.011600 / 0.002430 / 0.015469
-Epoch/Batch: 0 / 9
-Mean/SD Pen: -0.022328 / 0.008056
Loss/Mean/SD: -0.014016 / 0.003970 / 0.016233
-Epoch/Batch: 0 / 10
-Mean/SD Pen: -0.027510 / 0.010014
Loss/Mean/SD: -0.016941 / 0.008366 / 0.021780
-Epoch/Batch: 0 / 11
-Mean/SD Pen: -0.022737 / 0.009526
Loss/Mean/SD: -0.012666 / 0.004236 / 0.020357
-Epoch/Batch: 0 / 12
-Mean/SD Pen: -0.027759 / 0.009540
Loss/Mean/SD: -0.017804 / 0.008639 / 0.020398
-Epoch/Batch: 0 / 13
-Mean/SD Pen: -0.026306 / 0.011017
Loss/Mean/SD: -0.014939 / 0.007130 / 0.024780
-Epoch/Batch: 0 / 14
-Mean/SD Pen: -0.019945 / 0.006366
Loss/Mean/SD: -0.013375 / 0.002653 / 0.011809
-Epoch/Batch: 1 / 0
-Mean/SD Pen: -0.019307 / 0.005232
Loss/Mean/SD: -0.013954 / 0.002362 / 0.009058
-Epoch/Batch: 1 / 1
-Mean/SD Pen: -0.022773 / 0.005116
Loss/Mean/SD: -0.017588 / 0.004260 / 0.008788
-Epoch/Batch: 1 / 2
-Mean/SD Pen: -0.022422 / 0.004893
Loss/Mean/SD: -0.017462 / 0.004030 / 0.008276
-Epoch/Batch: 1 / 3
-Mean/SD Pen: -0.026173 / 0.006548
Loss/Mean/SD: -0.019551 / 0.007002 / 0.012266
-Epoch/Batch: 1 / 4
-Mean/SD Pen: -0.022462 / 0.005426
Loss/Mean/SD: -0.016895 / 0.004056 / 0.009515
-Epoch/Batch: 1 / 5
-Mean/SD Pen: -0.025921 / 0.005619
Loss/Mean/SD: -0.020125 / 0.006764 / 0.009976
-Epoch/Batch: 1 / 6
-Mean/SD Pen: -0.025916 / 0.006369
Loss/Mean/SD: -0.019354 / 0.006759 / 0.011816
-Epoch/Batch: 1 / 7
-Mean/SD Pen: -0.025007 / 0.005814
Loss/Mean/SD: -0.019013 / 0.005950 / 0.010445
-Epoch/Batch: 1 / 8
-Mean/SD Pen: -0.027344 / 0.007182
Loss/Mean/SD: -0.019951 / 0.008187 / 0.013899
-Epoch/Batch: 1 / 9
-Mean/SD Pen: -0.026285 / 0.005597
Loss/Mean/SD: -0.020514 / 0.007110 / 0.009922
-Epoch/Batch: 1 / 10
-Mean/SD Pen: -0.025489 / 0.005045
Loss/Mean/SD: -0.020310 / 0.006370 / 0.008625
-Epoch/Batch: 1 / 11
-Mean/SD Pen: -0.024202 / 0.005707
Loss/Mean/SD: -0.018357 / 0.005294 / 0.010187
-Epoch/Batch: 1 / 12
-Mean/SD Pen: -0.023853 / 0.005243
Loss/Mean/SD: -0.018499 / 0.005026 / 0.009084
-Epoch/Batch: 1 / 13
-Mean/SD Pen: -0.015452 / 0.004775
Loss/Mean/SD: -0.010606 / 0.001066 / 0.008005
-Epoch/Batch: 1 / 14
-Mean/SD Pen: -0.025243 / 0.005275
Loss/Mean/SD: -0.019861 / 0.006154 / 0.009159
-Epoch/Batch: 2 / 0
-Mean/SD Pen: -0.025561 / 0.005416
Loss/Mean/SD: -0.020025 / 0.006435 / 0.009493
-Epoch/Batch: 2 / 1
-Mean/SD Pen: -0.023301 / 0.004937
Loss/Mean/SD: -0.018226 / 0.004623 / 0.008376
-Epoch/Batch: 2 / 2
-Mean/SD Pen: -0.024324 / 0.004665
Loss/Mean/SD: -0.019553 / 0.005390 / 0.007757
-Epoch/Batch: 2 / 3
-Mean/SD Pen: -0.021773 / 0.004467
Loss/Mean/SD: -0.017222 / 0.003629 / 0.007316
-Epoch/Batch: 2 / 4
-Mean/SD Pen: -0.022436 / 0.003744
Loss/Mean/SD: -0.018601 / 0.004039 / 0.005763
-Epoch/Batch: 2 / 5
-Mean/SD Pen: -0.020723 / 0.004338
Loss/Mean/SD: -0.016298 / 0.003041 / 0.007033
-Epoch/Batch: 2 / 6
-Mean/SD Pen: -0.023848 / 0.005291
Loss/Mean/SD: -0.018429 / 0.005023 / 0.009196
-Epoch/Batch: 2 / 7
-Mean/SD Pen: -0.025974 / 0.005301
Loss/Mean/SD: -0.020539 / 0.006814 / 0.009219
-Epoch/Batch: 2 / 8
-Mean/SD Pen: -0.020621 / 0.004733
Loss/Mean/SD: -0.015790 / 0.002988 / 0.007910
-Epoch/Batch: 2 / 9
-Mean/SD Pen: -0.021691 / 0.003908
Loss/Mean/SD: -0.017701 / 0.003580 / 0.006106
-Epoch/Batch: 2 / 10
-Mean/SD Pen: -0.025155 / 0.004616
Loss/Mean/SD: -0.020450 / 0.006077 / 0.007648
-Epoch/Batch: 2 / 11
-Mean/SD Pen: -0.022329 / 0.004089
Loss/Mean/SD: -0.018176 / 0.003971 / 0.006493
-Epoch/Batch: 2 / 12
-Mean/SD Pen: -0.022758 / 0.004119
Loss/Mean/SD: -0.018565 / 0.004250 / 0.006557
-Epoch/Batch: 2 / 13
-Mean/SD Pen: -0.021541 / 0.004861
Loss/Mean/SD: -0.016605 / 0.003492 / 0.008203
-Epoch/Batch: 2 / 14
-Mean/SD Pen: -0.022216 / 0.003960
Loss/Mean/SD: -0.018186 / 0.003899 / 0.006217
[Data] Using cached data from csv/prices.csv
[Cross-Rank] Failed for JPM: 'close'
[Cross-Rank] Failed for LLY: 'close'
[Cross-Rank] Failed for MA: 'close'
/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
Traceback (most recent call last):
  File "/Users/diegomontemayor/algo_trader/model.py", line 102, in <module>
    results = run_btest(device=DEVICE,initial_capital=INITIAL_CAPITAL,
  File "/Users/diegomontemayor/algo_trader/test.py", line 28, in run_btest
    feat_df, ret_df = comp_feat(TICK, feat, cached_data, macro_keys)
  File "/Users/diegomontemayor/algo_trader/feat.py", line 114, in comp_feat
    if ret.iloc[-1].isna().all():
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexing.py", line 1191, in __getitem__
    return self._getitem_axis(maybe_callable, axis=axis)
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexing.py", line 1752, in _getitem_axis
    self._validate_integer(key, axis)
  File "/Users/diegomontemayor/algo_trader/venv/lib/python3.9/site-packages/pandas/core/indexing.py", line 1685, in _validate_integer
    raise IndexError("single positional indexer is out-of-bounds")
IndexError: single positional indexer is out-of-bounds

=== Trial output end ===
